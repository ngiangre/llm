{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc38bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chatlas\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd241e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the recipes from the text files (this time all of the files)\n",
    "from pyhere import here\n",
    "\n",
    "recipe_files = list(here(\"data/recipes/text\").glob(\"*\"))\n",
    "recipes = [f.read_text() for f in recipe_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c987c",
   "metadata": {},
   "source": [
    "We'll use the same Pydantic models we defined in `10_structured-output`.\n",
    "Optional: Replace the models in the next cell with your own from that\n",
    "exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Ingredient(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the ingredient\")\n",
    "    quantity: float | None = Field(default=1, description=\"Quantity as provided\")\n",
    "    unit: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Unit of measure, if applicable\",\n",
    "    )\n",
    "    notes: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Additional notes or preparation details\",\n",
    "    )\n",
    "\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "    image_url: Optional[str] = Field(..., description=\"URL of an image of the dish\")\n",
    "    ingredients: List[Ingredient]\n",
    "    instructions: List[str] = Field(..., description=\"Step-by-step instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c1f51",
   "metadata": {},
   "source": [
    "First, we'll use a simple loop to process each recipe one at a time. This is\n",
    "straightforward for our 8 recipes, but would be slow (and expensive) for a\n",
    "larger dataset.\n",
    "\n",
    "In a future version of `chatlas` (soon after conf!), you will be able to use\n",
    "`chatlas.parallel_chat_structured()` to do this truly in parallel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def extract_recipe(recipe_text: str) -> Recipe:\n",
    "    chat = chatlas.ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "    return chat.chat_structured(recipe_text, data_model=Recipe)\n",
    "\n",
    "\n",
    "recipes_data: List[Recipe] = []\n",
    "for recipe in tqdm(recipes):\n",
    "    recipes_data.append(extract_recipe(recipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[r.title for r in recipes_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can that be a polars DataFrame?\n",
    "import polars as pl\n",
    "\n",
    "recipes_df = pl.DataFrame([r.model_dump() for r in recipes_data], strict=False)\n",
    "recipes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578b416",
   "metadata": {},
   "source": [
    "That was pretty easy! But what if we had 10,000 recipes to process? That would\n",
    "take a long time, and be pretty expensive. We can save money by using the\n",
    "Batch API, which allows us to send multiple requests in a single API call.\n",
    "\n",
    "With the Batch API, results are processed asynchronously and are completed at\n",
    "some point, usually within a few minutes but at most within the next 24 hours.\n",
    "Because batching lets providers schedule requests more efficiently, it also\n",
    "costs less per token than the standard API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f71795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatlas import batch_chat_structured\n",
    "\n",
    "chat = chatlas.ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
    "res = ____(\n",
    "    chat=chat,\n",
    "    prompts=____,\n",
    "    data_model=____,\n",
    "    path=here(\"data/recipes/batch_results_py_claude.json\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d37e8",
   "metadata": {},
   "source": [
    "Now, save the results to a JSON file in `data/recipes/recipes.json`. Once\n",
    "you've done that, you can open up `11_recipe-app.py` and run the app to see\n",
    "your new recipe collection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "recipes_structured = [r.model_dump() for r in res]\n",
    "\n",
    "json.dump(recipes_structured, open(here(\"data/recipes/recipes.json\"), \"w\"), indent=2)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
