{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cc0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from chatlas import ChatAuto\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bf4572",
   "metadata": {},
   "source": [
    "List models by calling the `list_models` method on a `Chat` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatAuto(____).list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c3a4a",
   "metadata": {},
   "source": [
    "You can also load the models into a Polars DataFrame for easier viewing.\n",
    "Use this block to list OpenAI and Anthropic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90062112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "models = ChatAuto(\"____\").list_models()\n",
    "models = pl.DataFrame(models)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b338d",
   "metadata": {},
   "source": [
    "Now try sending the same prompt to different models to compare the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e09b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a  recipe for an easy weeknight dinner my kids would like.\"\n",
    "\n",
    "ChatAuto(\"____\").chat(prompt)\n",
    "ChatAuto(\"____\").chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f26fbc",
   "metadata": {},
   "source": [
    "Bonus: local models?\n",
    "\n",
    "If you have local models installed, try them out with Ollama. Note that you\n",
    "have to give a model name to list models, but the model name can be anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7a4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatAuto(\"ollama/any-model-name\").list_models()\n",
    "ChatAuto(\"ollama/gemma3:4b\").chat(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07714be6",
   "metadata": {},
   "source": [
    "Bonus: Rewrite your `ChatAuto()` calls to use the direct provider functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1723b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatlas import ChatAnthropic, ChatOpenAI\n",
    "\n",
    "Chat____(____)\n",
    "Chat____(____)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
